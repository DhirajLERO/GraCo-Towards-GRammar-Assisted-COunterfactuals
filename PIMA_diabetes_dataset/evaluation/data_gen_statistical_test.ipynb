{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating CF generation\n",
    "1. Probability Increase\n",
    "2. proximity\n",
    "3. sparsity\n",
    "4. Cohesive\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cee158c0c843ea0"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:38:19.275668Z",
     "start_time": "2024-07-24T14:38:19.220065Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    return np.load(data)\n",
    "\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(8, 32)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(32, 64)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(64, 16)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(16, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def load_model(input_folder = 'model_training/model'):\n",
    "    model = torch.load(input_folder)\n",
    "    model.eval()\n",
    "    return model\n",
    "    \n",
    "def eval_model(model, input):\n",
    "    # print(input)\n",
    "    with torch.no_grad():\n",
    "        prob = model(input)\n",
    "    return prob.tolist()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:20:19.026338Z",
     "start_time": "2024-07-24T14:20:19.022140Z"
    }
   },
   "id": "8969eff1405bb6aa",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = load_model(input_folder = './../model_training/model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:20:19.374439Z",
     "start_time": "2024-07-24T14:20:19.336773Z"
    }
   },
   "id": "1665656a23b106ab",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate average probability shift"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68314a2b941807f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_model_for_df(df , model):\n",
    "    probability_list = []\n",
    "    if df.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for index, row in df.iterrows():\n",
    "            x = row.to_numpy()\n",
    "            prob = eval_model(model, torch.tensor(x, dtype=torch.float32))\n",
    "            probability_list.append(prob)\n",
    "        return sum(probability_list)/len(probability_list)\n",
    "        \n",
    "\n",
    "def average_probability_shift(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, model):\n",
    "    metric_dict = {'initial_prob' : [],\n",
    "                   'dice_prob' : [],\n",
    "                   'Our_method_prob' : [],\n",
    "                   'certif_prob' : [],\n",
    "                   'GE_NSGAII_prob': []}\n",
    "        \n",
    "    for i in os.listdir(input_data_loc):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        # print(i)\n",
    "        input_array_location = input_data_loc + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        prob = eval_model(model,  torch.tensor(input, dtype=torch.float32))\n",
    "        # print(prob)\n",
    "        dice_df = pd.read_csv(dice_loc +  i + '.csv')\n",
    "        dice_df.drop(columns=['outcome'], inplace=True)\n",
    "        Our_method_df  = pd.read_csv(ge_cf_loc +  i + '.csv')\n",
    "        certif_df = pd.read_csv(certif_cf_loc +  i + '.csv')\n",
    "        NSGAII_df = pd.read_csv(ge_nsga2_loc +  i + '.csv')\n",
    "        \n",
    "        metric_dict['initial_prob'].append(prob)\n",
    "        metric_dict['dice_prob'].append(evaluate_model_for_df(dice_df, model))\n",
    "        metric_dict['Our_method_prob'].append(evaluate_model_for_df(Our_method_df, model))\n",
    "        metric_dict['certif_prob'].append(evaluate_model_for_df(certif_df, model))\n",
    "        metric_dict['GE_NSGAII_prob'].append(evaluate_model_for_df(NSGAII_df, model))\n",
    "        \n",
    "    return metric_dict\n",
    "\n",
    "def save_dict(d, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:40:01.997627Z",
     "start_time": "2024-07-24T14:40:01.989770Z"
    }
   },
   "id": "7de9c4d4131c6ad4",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_data_loc = './../output/NSGAIII/'\n",
    "dice_loc = 'Dice_cf/'\n",
    "ge_cf_loc = 'Ge_cf/'\n",
    "ge_nsga2_loc = 'Ge_NSGAII_cf/'\n",
    "certif_cf_loc = 'Certif_cf/'\n",
    "\n",
    "metric = average_probability_shift(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:40:09.564931Z",
     "start_time": "2024-07-24T14:40:08.563793Z"
    }
   },
   "id": "38e1198c798d2e19",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def average_shift(metric):\n",
    "    metric_dict = {}\n",
    "    dice_shift = []\n",
    "    our_method_shift = []\n",
    "    certif_shift = []\n",
    "    nsga2_shift = []\n",
    "    for i in range(0, 30):\n",
    "        if metric['dice_prob'][i]!= 0:\n",
    "            dice_shift.append(metric['dice_prob'][i] - metric['initial_prob'][i])\n",
    "        else:\n",
    "            dice_shift.append(0)\n",
    "        \n",
    "        if metric['Our_method_prob'][i]!= 0:\n",
    "            our_method_shift.append(metric['Our_method_prob'][i] - metric['initial_prob'][i])\n",
    "        else:\n",
    "            our_method_shift.append(0)\n",
    "        \n",
    "        if metric['certif_prob'][i]!= 0:\n",
    "            certif_shift.append(metric['certif_prob'][i] - metric['initial_prob'][i])\n",
    "        else:\n",
    "            certif_shift.append(0)\n",
    "        \n",
    "        if metric['GE_NSGAII_prob'][i]!= 0:\n",
    "            nsga2_shift.append(metric['GE_NSGAII_prob'][i] - metric['initial_prob'][i])\n",
    "        else:\n",
    "            nsga2_shift.append(0)\n",
    "        \n",
    "    \n",
    "    metric_dict['Dice'] =     sum(dice_shift)/len(dice_shift)\n",
    "    metric_dict['Certif'] = sum(certif_shift)/len(certif_shift)\n",
    "    metric_dict['Our_method'] = sum(our_method_shift)/len(our_method_shift)\n",
    "    metric_dict['GE_NSGAII'] = sum(nsga2_shift)/len(nsga2_shift)\n",
    "    \n",
    "    d = {'Dice': dice_shift, 'Certif': certif_shift,\n",
    "                              'Our_method': our_method_shift, 'GE_NSGAII':nsga2_shift}\n",
    "    \n",
    "\n",
    "    \n",
    "    return metric_dict, d\n",
    "        \n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:40:09.569678Z",
     "start_time": "2024-07-24T14:40:09.565940Z"
    }
   },
   "id": "21cba13d29a232e8",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output, daf = average_shift(metric)\n",
    "save_dict(daf, 'data_statistical_test/average_shift.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:40:41.407719Z",
     "start_time": "2024-07-24T14:40:41.400545Z"
    }
   },
   "id": "b6593fd4afc93164",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d938705b10b822fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Proximity comparison : average distance of counterfactuals from input \n",
    "- lower the better"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be6ec7326fec628b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "def calculate_l2_distance_sklearn(array, df):\n",
    "    \n",
    "    # Create a DistanceMetric object for Euclidean distance\n",
    "    if df.shape[0] == 0:\n",
    "        print(\"no counterfactuals\")\n",
    "        return []\n",
    "    \n",
    "    euclidean = DistanceMetric.get_metric('euclidean')\n",
    "    \n",
    "    # Ensure array is 2D for pairwise\n",
    "    array_2d = array.reshape(1, -1)\n",
    "    \n",
    "    # Calculate distances using the pairwise method\n",
    "    distances = euclidean.pairwise(array_2d, df.values)\n",
    "    \n",
    "    # Convert distances to a list\n",
    "    distances_list = distances.flatten().tolist()\n",
    "    \n",
    "    return distances_list\n",
    "\n",
    "\n",
    "def calculate_proximity(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, model):\n",
    "    metric_dict = {'Dice' : [],\n",
    "                   'Our_method' : [],\n",
    "                   'Certif' : [],\n",
    "                   'GE_NSGAII': []}\n",
    "        \n",
    "    for i in os.listdir(input_data_loc):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        # print(i)\n",
    "        input_array_location = input_data_loc + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        # print(i)\n",
    "        # print(prob)\n",
    "        dice_df = pd.read_csv(dice_loc +  i + '.csv')\n",
    "        dice_df.drop(columns=['outcome'], inplace=True)\n",
    "        Our_method_df  = pd.read_csv(ge_cf_loc +  i + '.csv')\n",
    "        certif_df = pd.read_csv(certif_cf_loc +  i + '.csv')\n",
    "        NSGAII_df = pd.read_csv(ge_nsga2_loc +  i + '.csv')\n",
    "        \n",
    "        if dice_df.shape[0] > 0:\n",
    "            metric_dict['Dice'].append(mean(calculate_l2_distance_sklearn(input, dice_df)))\n",
    "        if Our_method_df.shape[0] > 0:\n",
    "            metric_dict['Our_method'].append(mean(calculate_l2_distance_sklearn(input, Our_method_df)))\n",
    "        if certif_df.shape[0] > 0:\n",
    "            metric_dict['Certif'].append(mean(calculate_l2_distance_sklearn(input, certif_df)))\n",
    "        if NSGAII_df.shape[0] > 0:\n",
    "            metric_dict['GE_NSGAII'].append(mean(calculate_l2_distance_sklearn(input, NSGAII_df)))\n",
    "    \n",
    "    d = {'Dice': metric_dict['Dice'], 'Certif': metric_dict['Certif'],\n",
    "                              'Our_method': metric_dict['Our_method'], 'GE_NSGAII':metric_dict['GE_NSGAII']}\n",
    "    \n",
    "    # print(d)\n",
    "    out_metric = {}\n",
    "    for key, value in metric_dict.items():\n",
    "        out_metric[key] = mean(value)\n",
    "    return out_metric, d\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:30:06.583949Z",
     "start_time": "2024-07-24T14:30:04.173850Z"
    }
   },
   "id": "4d0024147abe66e2",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'Dice': 375.8579123404342,\n 'Our_method': 58.54761684658484,\n 'Certif': 60.09701095190148,\n 'GE_NSGAII': 56.535571946582266}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proximity, d_proximity = calculate_proximity(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, model)\n",
    "\n",
    "save_dict(d_proximity, 'data_statistical_test/proximity.pickle')\n",
    "\n",
    "proximity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:41:20.351556Z",
     "start_time": "2024-07-24T14:41:20.249721Z"
    }
   },
   "id": "31f126fbcb790215",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sparsity: Average feature change in inputs\n",
    "- lower the better"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3e3066357d08d27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_feature_changes(array, df):\n",
    "    changes = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Compare array with row and count the number of differences\n",
    "        # print('row {} and array {}'.format(row.values, array))\n",
    "        num_changes = np.sum(array != row.values)\n",
    "        # print('num_changes: {}'.format(num_changes))\n",
    "        changes.append(num_changes)\n",
    "    return changes\n",
    "\n",
    "\n",
    "def calculate_sparsity(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, model):\n",
    "    metric_dict = {'Dice' : [],\n",
    "                   'Our_method' : [],\n",
    "                   'Certif' : [],\n",
    "                   'GE_NSGAII': []}\n",
    "        \n",
    "    for i in os.listdir(input_data_loc):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        # print(i)\n",
    "        input_array_location = input_data_loc + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        # print(i)\n",
    "        # print(prob)\n",
    "        dice_df = pd.read_csv(dice_loc +  i + '.csv')\n",
    "        dice_df.drop(columns=['outcome'], inplace=True)\n",
    "        Our_method_df  = pd.read_csv(ge_cf_loc +  i + '.csv')\n",
    "        certif_df = pd.read_csv(certif_cf_loc +  i + '.csv')\n",
    "        NSGAII_df = pd.read_csv(ge_nsga2_loc +  i + '.csv')\n",
    "        \n",
    "        if dice_df.shape[0] > 0:\n",
    "            metric_dict['Dice'].append(mean(calculate_feature_changes(input, dice_df)))\n",
    "        if Our_method_df.shape[0] > 0:\n",
    "            metric_dict['Our_method'].append(mean(calculate_feature_changes(input, Our_method_df)))\n",
    "        if certif_df.shape[0] > 0:\n",
    "            metric_dict['Certif'].append(mean(calculate_feature_changes(input, certif_df)))\n",
    "        if NSGAII_df.shape[0] > 0:\n",
    "            metric_dict['GE_NSGAII'].append(mean(calculate_feature_changes(input, NSGAII_df)))\n",
    "    \n",
    "    d = {'Dice': metric_dict['Dice'], 'Certif': metric_dict['Certif'],\n",
    "                              'Our_method': metric_dict['Our_method'], 'GE_NSGAII':metric_dict['GE_NSGAII']}\n",
    "    \n",
    "    # print(d)\n",
    "    \n",
    "    \n",
    "    out_metric = {}\n",
    "    for key, value in metric_dict.items():\n",
    "        out_metric[key] = mean(value)\n",
    "    return out_metric, d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:32:38.925867Z",
     "start_time": "2024-07-24T14:32:38.909125Z"
    }
   },
   "id": "f08d8061cecc6e3d",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'Dice': 1.7296210155694045,\n 'Our_method': 3.41060951585735,\n 'Certif': 7.996666666666667,\n 'GE_NSGAII': 3.5505844448873463}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity, d_sparsity = calculate_sparsity(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, model)\n",
    "\n",
    "save_dict(d_sparsity, 'data_statistical_test/sparsity.pickle')\n",
    "\n",
    "sparsity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:42:13.644819Z",
     "start_time": "2024-07-24T14:42:13.486216Z"
    }
   },
   "id": "1f9c42141524fe11",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cohesive : how close these individuals are with each other\n",
    "1. normalized Average distance between all the individual with the centroid of data \n",
    "2. higher the better"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d768591e16045fb5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def distance_between_all_counterfactuals(df):\n",
    "    if not df.applymap(lambda x: isinstance(x, (int, float))).all().all():\n",
    "        raise ValueError(\"DataFrame contains non-numeric data.\")\n",
    "    \n",
    "    data = df.values\n",
    "    euclidean = DistanceMetric.get_metric('euclidean')\n",
    "    dist_matrix = euclidean.pairwise(data)\n",
    "    \n",
    "    distances = []\n",
    "    n = len(dist_matrix)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            distances.append(dist_matrix[i, j])\n",
    "    \n",
    "    return distances\n",
    "\n",
    "def calculate_cohesive(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, model):\n",
    "    metric_dict = {'Dice' : [],\n",
    "                   'Our_method' : [],\n",
    "                   'Certif' : [],\n",
    "                   'GE_NSGAII': []}\n",
    "        \n",
    "    for i in os.listdir(input_data_loc):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        # print(i)\n",
    "        input_array_location = input_data_loc + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        # print(i)\n",
    "        # print(prob)\n",
    "        dice_df = pd.read_csv(dice_loc +  i + '.csv')\n",
    "        dice_df.drop(columns=['outcome'], inplace=True)\n",
    "        Our_method_df  = pd.read_csv(ge_cf_loc +  i + '.csv')\n",
    "        certif_df = pd.read_csv(certif_cf_loc +  i + '.csv')\n",
    "        NSGAII_df = pd.read_csv(ge_nsga2_loc +  i + '.csv')\n",
    "    \n",
    "        if dice_df.shape[0] > 1:\n",
    "            metric_dict['Dice'].append(mean(distance_between_all_counterfactuals(dice_df)))\n",
    "        if Our_method_df.shape[0] > 1:\n",
    "            metric_dict['Our_method'].append(mean(distance_between_all_counterfactuals(Our_method_df)))\n",
    "        if certif_df.shape[0] > 1:\n",
    "            metric_dict['Certif'].append(mean(distance_between_all_counterfactuals(certif_df)))\n",
    "        if NSGAII_df.shape[0] > 1:\n",
    "            metric_dict['GE_NSGAII'].append(mean(distance_between_all_counterfactuals(NSGAII_df)))\n",
    "    \n",
    "    d = {'Dice': metric_dict['Dice'], 'Certif': metric_dict['Certif'],\n",
    "                              'Our_method': metric_dict['Our_method'], 'GE_NSGAII':metric_dict['GE_NSGAII']}\n",
    "    \n",
    " \n",
    "    \n",
    "    out_metric = {}\n",
    "    for key, value in metric_dict.items():\n",
    "        out_metric[key] = 1/mean(value)\n",
    "    return out_metric, d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:42:57.085406Z",
     "start_time": "2024-07-24T14:42:57.078659Z"
    }
   },
   "id": "8e7416f0489b099",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cohesive, d_cohesive = calculate_cohesive(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, model)\n",
    "\n",
    "save_dict(d_cohesive, 'data_statistical_test/cohesive.pickle')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:42:57.770559Z",
     "start_time": "2024-07-24T14:42:57.620072Z"
    }
   },
   "id": "a1f36ae08e30863f",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dice': 0.1761597439467549, 'Our_method': 0.3404403582388863, 'Certif': 0.16063577411069954, 'GE_NSGAII': 0.3227641237036593}\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def normalize_dict(data_dict):\n",
    "    values = np.array(list(data_dict.values())).reshape(1, -1)\n",
    "    normalized_values = normalize(values, norm='l1')[0]\n",
    "    normalized_dict = {key: normalized_values[i] for i, key in enumerate(data_dict.keys())}\n",
    "    return normalized_dict\n",
    "\n",
    "def find_mu_sigma(input_data_loc, output_column_name):\n",
    "    data = pd.read_csv(input_data_loc)\n",
    "    data.drop([output_column_name, 'Unnamed: 0'], axis=1, inplace=True)\n",
    "    mu = np.mean(data.values, axis=0)\n",
    "    sigma = np.cov(data.values.T)\n",
    "    return mu, sigma\n",
    "\n",
    "\n",
    "def mean_mahabolis_distances(df, mu, sigma):\n",
    "    dist= []\n",
    "    for index, row in df.iterrows():\n",
    "        x = row.to_numpy()\n",
    "        d = mahalanobis(x, mu, np.linalg.inv(sigma))\n",
    "        dist.append(d)\n",
    "    return mean(dist)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "def closer_to_data_manifold(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, output_column_name, input_file_name):\n",
    "    metric_dict = {'Dice' : [],\n",
    "                   'Our_method' : [],\n",
    "                   'Certif' : [],\n",
    "                   'GE_NSGAII': []}\n",
    "    \n",
    "    mu, sigma = find_mu_sigma(input_file_name, output_column_name)\n",
    "        \n",
    "    for i in os.listdir(input_data_loc):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        # print(i)\n",
    "        input_array_location = input_data_loc + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        dice_df = pd.read_csv(dice_loc +  i + '.csv')\n",
    "        dice_df.drop(columns=['outcome'], inplace=True)\n",
    "        Our_method_df  = pd.read_csv(ge_cf_loc +  i + '.csv')\n",
    "        certif_df = pd.read_csv(certif_cf_loc +  i + '.csv')\n",
    "        NSGAII_df = pd.read_csv(ge_nsga2_loc +  i + '.csv')\n",
    "    \n",
    "        if dice_df.shape[0] > 1:\n",
    "            metric_dict['Dice'].append(mean_mahabolis_distances(dice_df, mu, sigma))\n",
    "        if Our_method_df.shape[0] > 1:\n",
    "            metric_dict['Our_method'].append(mean_mahabolis_distances(Our_method_df, mu, sigma))\n",
    "        if certif_df.shape[0] > 1:\n",
    "            metric_dict['Certif'].append(mean_mahabolis_distances(certif_df, mu, sigma))\n",
    "        if NSGAII_df.shape[0] > 1:\n",
    "            metric_dict['GE_NSGAII'].append(mean_mahabolis_distances(NSGAII_df, mu, sigma))\n",
    "    \n",
    "    \n",
    "    d = {'Dice': metric_dict['Dice'], 'Certif': metric_dict['Certif'],\n",
    "                              'Our_method': metric_dict['Our_method'], 'GE_NSGAII':metric_dict['GE_NSGAII']}\n",
    "    \n",
    "    \n",
    "    out_metric = {}\n",
    "    for key, value in metric_dict.items():\n",
    "        out_metric[key] = 1/mean(value)\n",
    "    \n",
    "    out_metric = normalize_dict(out_metric)\n",
    "    \n",
    "    return out_metric, d\n",
    "\n",
    "input_file_name = './../model_training/test.csv'\n",
    "output_column_name = 'Outcome'\n",
    "\n",
    "conformity_dict, d_conformity = closer_to_data_manifold(input_data_loc, dice_loc, ge_cf_loc, ge_nsga2_loc, certif_cf_loc, output_column_name, input_file_name)\n",
    "print(conformity_dict)\n",
    "\n",
    "save_dict(d_conformity, 'data_statistical_test/conformity.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T14:47:42.528543Z",
     "start_time": "2024-07-24T14:47:41.856462Z"
    }
   },
   "id": "bcdbf1ffd5e8c8d4",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "## goodness of counterfactuals \n",
    "goodness = (avg_probability_increase * cohesiveness * Conformity)/(proximity * sparsity)\n",
    "- avg_probability_increase : increase the average probability of class\n",
    "- cohesiveness : generated counterfactuals should be close to each other\n",
    "- proximity: close to the input space\n",
    "- sparsity: minimum feature change\n",
    "- conformity : closeness to data manifold \n",
    "- higher is better"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d79ef96255f5c2e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'Dice': 0.008009241419037116,\n 'Certif': 0.0486691905437965,\n 'Our_method': 0.48953090592924686,\n 'GE_NSGAII': 0.45379066210791935}"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def goodness_of_cf(avg_prob_dict, cohesive_dict,  proximity_dict, sparsity_dict, conformity_dict):\n",
    "    goodness_of_cf_dict = {}\n",
    "    for key, value in avg_prob_dict.items():\n",
    "        goodness_of_cf_dict[key] = (avg_prob_dict[key] * cohesive_dict[key] * conformity_dict[key])/(proximity_dict[key] * sparsity_dict[key])\n",
    "    return normalize_dict(goodness_of_cf_dict)\n",
    "\n",
    "goodness_of_cf = goodness_of_cf(output, cohesive, proximity, sparsity, conformity_dict)\n",
    "goodness_of_cf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T18:05:57.003222Z",
     "start_time": "2024-07-11T18:05:56.999319Z"
    }
   },
   "id": "a2de17cde8b331ee",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e362eabf3e875553"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
