{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T00:40:23.499530Z",
     "start_time": "2024-06-15T00:40:23.498019Z"
    }
   },
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(8, 32)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(32, 64)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(64, 16)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(16, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def load_model(input_folder = 'model_training/model'):\n",
    "    model = torch.load(input_folder)\n",
    "    model.eval()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T00:40:24.608913Z",
     "start_time": "2024-06-15T00:40:24.606532Z"
    }
   },
   "id": "37b1ad538e7272d4",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = load_model(input_folder = './../model_training/model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T00:40:25.491645Z",
     "start_time": "2024-06-15T00:40:25.467667Z"
    }
   },
   "id": "d622006bf8a2603e",
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    return np.load(data)\n",
    "\n",
    "\n",
    "def create_dataframe_from_list_of_arrays(arrays, column_names=None):\n",
    "    data= []\n",
    "    if not arrays:\n",
    "        raise ValueError(\"The list of arrays is empty\")\n",
    "    \n",
    "    # Check if all arrays have the same length\n",
    "    length = len(arrays[0])\n",
    "    if not all(len(arr) == length for arr in arrays):\n",
    "        raise ValueError(\"All arrays must have the same length\")\n",
    "    \n",
    "    # Create a dictionary for DataFrame creation\n",
    "\n",
    "    if len(column_names) != length:\n",
    "        print(len(column_names), len(arrays))\n",
    "        raise ValueError(\"Number of column names must match the number of arrays\")\n",
    "    for i in arrays:\n",
    "        data.append({column_names[j]: i[j] for j in range(len(i))})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def create_data(folder_location, column_names):\n",
    "    input_list = []\n",
    "    for i in os.listdir(folder_location):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        input_array_location = folder_location + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        print(input)\n",
    "        input_list.append(input)\n",
    "    \n",
    "    df = create_dataframe_from_list_of_arrays(input_list, column_names)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T00:40:27.228420Z",
     "start_time": "2024-06-15T00:40:27.225599Z"
    }
   },
   "id": "597c6f762ec32c3d",
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def apply_phenotype(array, phenotype):\n",
    "    # Split the phenotype string into individual operations\n",
    "    operations = phenotype.split(';')\n",
    "    x = copy.deepcopy(array)\n",
    "    # Iterate over each operation and execute it\n",
    "    for operation in operations:\n",
    "        # Strip any leading/trailing whitespace from the operation\n",
    "        operation = operation.strip()\n",
    "        \n",
    "        # Use the exec function to execute the operation on the array\n",
    "        if operation:\n",
    "            exec(operation)\n",
    "\n",
    "    return x\n",
    "\n",
    "def create_dice_cf(input_folder):\n",
    "    \n",
    "    features = [\"Pregnancies\",'Glucose','Blood Pressure','Skin Thickness','Insulin', 'BMI', 'DiabetesPedigreeFunction','Age']\n",
    "    backend = 'PYT'  # needs pytorch installed\n",
    "    ML_modelpath = './../model_training/model'\n",
    "    m = dice_ml.Model(model_path=ML_modelpath, backend=backend)\n",
    "    \n",
    "    d = dice_ml.Data(features={'Pregnancies': [0,17],\n",
    "                           'Glucose' : [25, 200],\n",
    "                           'Blood Pressure' : [20, 122],\n",
    "                           'Skin Thickness' : [0, 99],\n",
    "                           'Insulin' : [0, 846],\n",
    "                           'BMI' : [10, 67],\n",
    "                           'DiabetesPedigreeFunction': [0.060, 2.5000],\n",
    "                           'Age' : [0, 100] },\n",
    "                 outcome_name='outcome')\n",
    "\n",
    "    exp = dice_ml.Dice(d, m)\n",
    "    path_to_DICE_cf = 'Dice_cf'\n",
    "    path_to_GE_cf = 'Ge_cf'\n",
    "    \n",
    "    for i in os.listdir(input_folder):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        filename = input_folder + '/' + i + '/' \"final_gen.csv\"\n",
    "        input_array_location = input_folder + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        data = pd.read_csv(filename)\n",
    "        data = data.sort_values(by=['o_1'])\n",
    "        data = data[data['o_1'] < 0.50]\n",
    "        number_of_counterfactuals = data.shape[0]\n",
    "        # print(number_of_counterfactuals)\n",
    "        input_dice = pd.DataFrame(data=[input], columns=features)\n",
    "        print(number_of_counterfactuals)\n",
    "        dice_exp = exp.generate_counterfactuals(input_dice, total_CFs=number_of_counterfactuals, desired_class=\"opposite\")\n",
    "        isExist = os.path.exists(path_to_DICE_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_DICE_cf)\n",
    "        # print(dice_exp.cf_examples_list[0].final_cfs_df.head())\n",
    "        dice_exp.cf_examples_list[0].final_cfs_df.to_csv(path_or_buf= path_to_DICE_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "        evolved_x = []\n",
    "    \n",
    "        for phenotype in data['Phenotype'].tolist():\n",
    "            x_out = apply_phenotype(input, phenotype)\n",
    "            evolved_x.append(x_out)\n",
    "            \n",
    "        GE_df = pd.DataFrame(data=evolved_x, columns=features)\n",
    "        isExist = os.path.exists(path_to_GE_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_GE_cf)\n",
    "        GE_df.to_csv(path_to_GE_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T00:40:48.029446Z",
     "start_time": "2024-06-15T00:40:48.026390Z"
    }
   },
   "id": "1fa52ba3335ea32a",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 31.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 41.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 44.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.65it/s]\n"
     ]
    }
   ],
   "source": [
    "input_folder = './../output/NSGAIII/'\n",
    "create_dice_cf(input_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T00:40:50.934542Z",
     "start_time": "2024-06-15T00:40:49.865900Z"
    }
   },
   "id": "ad52ab336a622bb6",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_NSGAII_cf(input_folder):\n",
    "    \n",
    "    features = [\"Pregnancies\",'Glucose','Blood Pressure','Skin Thickness','Insulin', 'BMI', 'DiabetesPedigreeFunction','Age']\n",
    "\n",
    "    \n",
    "\n",
    "    path_to_NSGAII_cf = 'Ge_NSGAII_cf'\n",
    "    \n",
    "    for i in os.listdir(input_folder):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        filename = input_folder + '/' + i + '/' \"final_gen.csv\"\n",
    "        input_array_location = input_folder + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        data = pd.read_csv(filename)\n",
    "        data = data.sort_values(by=['o_1'])\n",
    "        data = data[data['o_1'] < 0.50]\n",
    "        number_of_counterfactuals = data.shape[0]\n",
    "        # print(number_of_counterfactuals)\n",
    "        \n",
    "        evolved_x = []\n",
    "    \n",
    "        for phenotype in data['Phenotype'].tolist():\n",
    "            x_out = apply_phenotype(input, phenotype)\n",
    "            evolved_x.append(x_out)\n",
    "            \n",
    "        GE_df = pd.DataFrame(data=evolved_x, columns=features)\n",
    "        isExist = os.path.exists(path_to_NSGAII_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_NSGAII_cf)\n",
    "        GE_df.to_csv(path_to_NSGAII_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "        \n",
    "input_folder = './../output/NSGAII_multi/'\n",
    "create_NSGAII_cf(input_folder)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T00:40:55.083477Z",
     "start_time": "2024-06-15T00:40:54.814159Z"
    }
   },
   "id": "9fd18d664e96dbc6",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b770c6da0ac34bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
