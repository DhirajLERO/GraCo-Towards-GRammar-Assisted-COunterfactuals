{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T09:51:09.119521Z",
     "start_time": "2024-06-15T09:51:04.330196Z"
    }
   },
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RiskClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(9, 16)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(16, 32)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(32, 64)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def load_model(input_folder = 'model_training/credit_risk_model'):\n",
    "    model = torch.load(input_folder)\n",
    "    model.eval()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T09:51:23.751762Z",
     "start_time": "2024-06-15T09:51:23.747711Z"
    }
   },
   "id": "37b1ad538e7272d4",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = load_model(input_folder = './../model_training/credit_risk_model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T09:51:24.604513Z",
     "start_time": "2024-06-15T09:51:24.592260Z"
    }
   },
   "id": "d622006bf8a2603e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    return np.load(data)\n",
    "\n",
    "\n",
    "def create_dataframe_from_list_of_arrays(arrays, column_names=None):\n",
    "    data= []\n",
    "    if not arrays:\n",
    "        raise ValueError(\"The list of arrays is empty\")\n",
    "    \n",
    "    # Check if all arrays have the same length\n",
    "    length = len(arrays[0])\n",
    "    if not all(len(arr) == length for arr in arrays):\n",
    "        raise ValueError(\"All arrays must have the same length\")\n",
    "    \n",
    "    # Create a dictionary for DataFrame creation\n",
    "\n",
    "    if len(column_names) != length:\n",
    "        print(len(column_names), len(arrays))\n",
    "        raise ValueError(\"Number of column names must match the number of arrays\")\n",
    "    for i in arrays:\n",
    "        data.append({column_names[j]: i[j] for j in range(len(i))})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def create_data(folder_location, column_names):\n",
    "    input_list = []\n",
    "    for i in os.listdir(folder_location):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        input_array_location = folder_location + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        print(input)\n",
    "        input_list.append(input)\n",
    "    \n",
    "    df = create_dataframe_from_list_of_arrays(input_list, column_names)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T09:51:31.652847Z",
     "start_time": "2024-06-15T09:51:31.649733Z"
    }
   },
   "id": "597c6f762ec32c3d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def apply_phenotype(array, phenotype):\n",
    "    # Split the phenotype string into individual operations\n",
    "    operations = phenotype.split(';')\n",
    "    x = copy.deepcopy(array)\n",
    "    # Iterate over each operation and execute it\n",
    "    for operation in operations:\n",
    "        # Strip any leading/trailing whitespace from the operation\n",
    "        operation = operation.strip()\n",
    "        \n",
    "        # Use the exec function to execute the operation on the array\n",
    "        if operation:\n",
    "            exec(operation)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_dice_cf(input_folder):\n",
    "    \n",
    "    features = ['Age','Sex','Job','Housing','Saving accounts','Checking account','Credit amount','Duration','Purpose']\n",
    "    backend = 'PYT'  # needs pytorch installed\n",
    "    ML_modelpath = './../model_training/credit_risk_model'\n",
    "    m = dice_ml.Model(model_path=ML_modelpath, backend=backend)\n",
    "    \n",
    "    d = dice_ml.Data(features={'Age': [18,80],\n",
    "                           'Sex' : [0, 1],\n",
    "                           'Job' : [0, 3],\n",
    "                           'Housing' : [0, 2],\n",
    "                           'Saving accounts' : [0, 3],\n",
    "                           'Checking account' : [0, 2],\n",
    "                           'Credit amount': [100.0, 50000.0],\n",
    "                           'Duration' : [3, 100],\n",
    "                           'Purpose' : [0, 7]  },\n",
    "                 outcome_name='outcome')\n",
    "\n",
    "    exp = dice_ml.Dice(d, m)\n",
    "    path_to_DICE_cf = 'Dice_cf'\n",
    "    path_to_GE_cf = 'Ge_cf'\n",
    "    \n",
    "    for i in os.listdir(input_folder):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        filename = input_folder + '/' + i + '/' \"final_gen.csv\"\n",
    "        input_array_location = input_folder + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        data = pd.read_csv(filename)\n",
    "        data = data.sort_values(by=['o_1'])\n",
    "        data = data[data['o_1'] < 0.50]\n",
    "        number_of_counterfactuals = data.shape[0]\n",
    "        # print(number_of_counterfactuals)\n",
    "        input_dice = pd.DataFrame(data=[input], columns=features)\n",
    "        print(number_of_counterfactuals)\n",
    "        dice_exp = exp.generate_counterfactuals(input_dice, total_CFs=number_of_counterfactuals, desired_class=\"opposite\")\n",
    "        isExist = os.path.exists(path_to_DICE_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_DICE_cf)\n",
    "        # print(dice_exp.cf_examples_list[0].final_cfs_df.head())\n",
    "        dice_exp.cf_examples_list[0].final_cfs_df.to_csv(path_or_buf= path_to_DICE_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "        evolved_x = []\n",
    "    \n",
    "        for phenotype in data['Phenotype'].tolist():\n",
    "            x_out = apply_phenotype(input, phenotype)\n",
    "            evolved_x.append(x_out)\n",
    "            \n",
    "        GE_df = pd.DataFrame(data=evolved_x, columns=features)\n",
    "        isExist = os.path.exists(path_to_GE_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_GE_cf)\n",
    "        GE_df.to_csv(path_to_GE_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T09:58:09.543660Z",
     "start_time": "2024-06-15T09:58:09.524114Z"
    }
   },
   "id": "1fa52ba3335ea32a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.22it/s]\n"
     ]
    }
   ],
   "source": [
    "input_folder = './../output/NSGAIII_multi/'\n",
    "create_dice_cf(input_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T09:58:11.799229Z",
     "start_time": "2024-06-15T09:58:11.039249Z"
    }
   },
   "id": "ad52ab336a622bb6",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_NSGAII_cf(input_folder):\n",
    "    \n",
    "    features = ['Age','Sex','Job','Housing','Saving accounts','Checking account','Credit amount','Duration','Purpose']\n",
    "\n",
    "    \n",
    "\n",
    "    path_to_NSGAII_cf = 'Ge_NSGAII_cf'\n",
    "    \n",
    "    for i in os.listdir(input_folder):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        filename = input_folder + '/' + i + '/' \"final_gen.csv\"\n",
    "        input_array_location = input_folder + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        data = pd.read_csv(filename)\n",
    "        data = data.sort_values(by=['o_1'])\n",
    "        data = data[data['o_1'] < 0.50]\n",
    "        number_of_counterfactuals = data.shape[0]\n",
    "        # print(number_of_counterfactuals)\n",
    "        \n",
    "        evolved_x = []\n",
    "    \n",
    "        for phenotype in data['Phenotype'].tolist():\n",
    "            x_out = apply_phenotype(input, phenotype)\n",
    "            evolved_x.append(x_out)\n",
    "            \n",
    "        GE_df = pd.DataFrame(data=evolved_x, columns=features)\n",
    "        isExist = os.path.exists(path_to_NSGAII_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_NSGAII_cf)\n",
    "        GE_df.to_csv(path_to_NSGAII_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "        \n",
    "input_folder = './../output/NSGAII_multi/'\n",
    "create_NSGAII_cf(input_folder)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T09:59:26.784383Z",
     "start_time": "2024-06-15T09:59:26.547086Z"
    }
   },
   "id": "9fd18d664e96dbc6",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b770c6da0ac34bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
