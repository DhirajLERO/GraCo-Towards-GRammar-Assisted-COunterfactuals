{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:07:32.182763Z",
     "start_time": "2024-06-29T22:07:30.788214Z"
    }
   },
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pickle import dump , load\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TaiwaneseCreditClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(23, 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 128)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(128, 32)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.hidden4 = nn.Linear(32, 16)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.output = nn.Linear(16, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.act1(self.hidden1(x)))\n",
    "        x = self.dropout(self.act2(self.hidden2(x)))\n",
    "        x = self.dropout(self.act3(self.hidden3(x)))\n",
    "        x = self.dropout(self.act4(self.hidden4(x)))\n",
    "        # x = self.output(x)\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def load_model():\n",
    "    model = torch.load('./../model_training/Taiwanese_credit_model')\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, input, scaler, columns_to_standardize):\n",
    "    model.eval()\n",
    "    # print(input)\n",
    "    input = input.reshape(-1, 23)\n",
    "    input = torch.tensor(input, dtype=torch.float32)\n",
    "    input = input.numpy()\n",
    "    input[:, columns_to_standardize] = scaler.transform(input[:, columns_to_standardize])\n",
    "    input = torch.from_numpy(input).type(torch.float)\n",
    "    with torch.no_grad():\n",
    "        prob = model(input)\n",
    "    return prob.tolist()[0][0]\n",
    "\n",
    "def load_scaler(scaler_loc):\n",
    "    return load(open(scaler_loc, 'rb'))\n",
    "\n",
    "columns_to_standardize = list(range(23))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:07:32.187037Z",
     "start_time": "2024-06-29T22:07:32.183375Z"
    }
   },
   "id": "37b1ad538e7272d4",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = load_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:07:32.190536Z",
     "start_time": "2024-06-29T22:07:32.187709Z"
    }
   },
   "id": "d622006bf8a2603e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    return np.load(data)\n",
    "\n",
    "\n",
    "def create_dataframe_from_list_of_arrays(arrays, column_names=None):\n",
    "    data= []\n",
    "    if not arrays:\n",
    "        raise ValueError(\"The list of arrays is empty\")\n",
    "    \n",
    "    # Check if all arrays have the same length\n",
    "    length = len(arrays[0])\n",
    "    if not all(len(arr) == length for arr in arrays):\n",
    "        raise ValueError(\"All arrays must have the same length\")\n",
    "    \n",
    "    # Create a dictionary for DataFrame creation\n",
    "\n",
    "    if len(column_names) != length:\n",
    "        print(len(column_names), len(arrays))\n",
    "        raise ValueError(\"Number of column names must match the number of arrays\")\n",
    "    for i in arrays:\n",
    "        data.append({column_names[j]: i[j] for j in range(len(i))})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def create_data(folder_location, column_names):\n",
    "    input_list = []\n",
    "    for i in os.listdir(folder_location):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        input_array_location = folder_location + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        print(input)\n",
    "        input_list.append(input)\n",
    "    \n",
    "    df = create_dataframe_from_list_of_arrays(input_list, column_names)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:07:32.194344Z",
     "start_time": "2024-06-29T22:07:32.191344Z"
    }
   },
   "id": "597c6f762ec32c3d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def scale_input(scaler, input, columns_to_standardize):\n",
    "    input = input.reshape(-1, 23)\n",
    "    input = torch.tensor(input, dtype=torch.float32)\n",
    "    input = input.numpy()\n",
    "    input[:, columns_to_standardize] = scaler.transform(input[:, columns_to_standardize])\n",
    "    return input\n",
    "\n",
    "\n",
    "def calculate_o_1(phenotype, input, model, scaler, columns_to_standardize):\n",
    "    mod_in = apply_phenotype(input, phenotype)\n",
    "    o_1 = eval_model(model, mod_in, scaler, columns_to_standardize)\n",
    "    return o_1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:08:03.172181Z",
     "start_time": "2024-06-29T22:08:03.167892Z"
    }
   },
   "id": "df5e5f857b75e42c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'X1': [-1.1320454, 6.6168604],\n 'X2': [-0.83086455, 1.4070086],\n 'X3': [-2.4233167, 5.3331966],\n 'X4': [-2.944624, 2.7857614],\n 'X5': [-1.6543822, 4.725081],\n 'X6': [-1.7442763, 6.0858283],\n 'X7': [-1.5366384, 5.869949],\n 'X8': [-1.5043159, 5.9613605],\n 'X9': [-1.4739374, 6.0869617],\n 'X10': [-1.4650515, 6.2978134],\n 'X11': [-1.4285109, 6.285492],\n 'X12': [-2.7501092, 12.224778],\n 'X13': [-1.6045824, 12.884915],\n 'X14': [-1.5517751, 11.600624],\n 'X15': [-1.8997005, 12.944077],\n 'X16': [0.2083898, 14.328156],\n 'X17': [-6.233661, 15.194207],\n 'X18': [-0.34022838, 60.5825],\n 'X19': [-0.27402094, 67.93915],\n 'X20': [-0.2800343, 52.843742],\n 'X21': [-0.3147646, 47.895416],\n 'X22': [-0.29640576, 28.63767],\n 'X23': [-0.28059798, 24.657183]}"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = load_scaler('./../model_training/StandardScaler.pkl')\n",
    "bounds= [(10000, 1000000),\n",
    "              (0, 1),\n",
    "              (0, 6),\n",
    "              (0, 3),\n",
    "              (20, 80),\n",
    "              (-2, 8),\n",
    "              (-2, 8),\n",
    "              (-2, 8),\n",
    "              (-2, 8),\n",
    "              (-2, 8),\n",
    "              (-2, 8),\n",
    "              (-154973, 964511),\n",
    "              (-67526, 983931),\n",
    "              (-61506, 855086),\n",
    "              (-81334, 891586),\n",
    "              (53007, 927171),\n",
    "              (-339603, 961664),\n",
    "              (0, 873552),\n",
    "              (0, 1215471),\n",
    "              (0, 846040),\n",
    "              (0, 621000),\n",
    "              (0, 417990),\n",
    "              (0, 403500)]\n",
    "min_array = np.array([i[0] for i in bounds])\n",
    "max_array = np.array([i[1] for i in bounds])\n",
    "scaled_min = scale_input(scaler, min_array, columns_to_standardize)\n",
    "scaled_max = scale_input(scaler, max_array, columns_to_standardize)\n",
    "\n",
    "feature = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11','X12', 'X13',\n",
    "            'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23']\n",
    "\n",
    "\n",
    "feature_dict = {}\n",
    "\n",
    "for i, j  in enumerate(bounds):\n",
    "    feature_dict[feature[i]] = [scaled_min[0][i], scaled_max[0][i]]\n",
    "\n",
    "feature_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:34:56.353010Z",
     "start_time": "2024-06-29T22:34:56.342711Z"
    }
   },
   "id": "dadff05f57ef1940",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.6168604  1.4070086  5.3331966  2.7857614  4.725081   6.0858283\n",
      "   5.869949   5.9613605  6.0869617  6.2978134  6.285492  12.224778\n",
      "  12.884915  11.600624  12.944077  14.328156  15.194207  60.5825\n",
      "  67.93915   52.843742  47.895416  28.63767   24.657183 ]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_max)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:34:57.438762Z",
     "start_time": "2024-06-29T22:34:57.435333Z"
    }
   },
   "id": "88be52cf047e8f72",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1320454  -0.83086455 -2.4233167  -2.944624   -1.6543822  -1.7442763\n",
      "  -1.5366384  -1.5043159  -1.4739374  -1.4650515  -1.4285109  -2.7501092\n",
      "  -1.6045824  -1.5517751  -1.8997005   0.2083898  -6.233661   -0.34022838\n",
      "  -0.27402094 -0.2800343  -0.3147646  -0.29640576 -0.28059798]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_min)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:34:58.914824Z",
     "start_time": "2024-06-29T22:34:58.911466Z"
    }
   },
   "id": "a783fedb4d70968f",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def apply_phenotype(array, phenotype):\n",
    "    # Split the phenotype string into individual operations\n",
    "    operations = phenotype.split(';')\n",
    "    x = copy.deepcopy(array)\n",
    "    # Iterate over each operation and execute it\n",
    "    for operation in operations:\n",
    "        # Strip any leading/trailing whitespace from the operation\n",
    "        operation = operation.strip()\n",
    "        \n",
    "        # Use the exec function to execute the operation on the array\n",
    "        if operation:\n",
    "            exec(operation)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def inverse(dice_df_scaled, scaler, columns_to_standardize):\n",
    "    df_values = dice_df_scaled.values\n",
    "    print(df_values.shape)\n",
    "    df_values[:, columns_to_standardize] = scaler.inverse_transform(df_values[:, columns_to_standardize])\n",
    "    df_original = pd.DataFrame(df_values, columns=dice_df_scaled.columns)\n",
    "    return df_original\n",
    "    \n",
    "\n",
    "\n",
    "def create_dice_cf(input_folder, scaler, model, columns_to_standardize):\n",
    "    \n",
    "    average_cf_count = []\n",
    "    \n",
    "    features = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11','X12', 'X13',\n",
    "            'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23']\n",
    "    backend = 'PYT'  # needs pytorch installed\n",
    "    ML_modelpath = './../model_training/Taiwanese_credit_model'\n",
    "    m = dice_ml.Model(model_path=ML_modelpath, backend=backend)\n",
    "    \n",
    "    d = dice_ml.Data(features={'X1': [-1.1320454, 6.6168604],\n",
    "                                 'X2': [-0.83086455, 1.4070086],\n",
    "                                 'X3': [-2.4233167, 5.3331966],\n",
    "                                 'X4': [-2.944624, 2.7857614],\n",
    "                                 'X5': [-1.6543822, 4.725081],\n",
    "                                 'X6': [-1.7442763, 6.0858283],\n",
    "                                 'X7': [-1.5366384, 5.869949],\n",
    "                                 'X8': [-1.5043159, 5.9613605],\n",
    "                                 'X9': [-1.4739374, 6.0869617],\n",
    "                                 'X10': [-1.4650515, 6.2978134],\n",
    "                                 'X11': [-1.4285109, 6.285492],\n",
    "                                 'X12': [-2.7501092, 12.224778],\n",
    "                                 'X13': [-1.6045824, 12.884915],\n",
    "                                 'X14': [-1.5517751, 11.600624],\n",
    "                                 'X15': [-1.8997005, 12.944077],\n",
    "                                 'X16': [0.2083898, 14.328156],\n",
    "                                 'X17': [-6.233661, 15.194207],\n",
    "                                 'X18': [-0.34022838, 60.5825],\n",
    "                                 'X19': [-0.27402094, 67.93915],\n",
    "                                 'X20': [-0.2800343, 52.843742],\n",
    "                                 'X21': [-0.3147646, 47.895416],\n",
    "                                 'X22': [-0.29640576, 28.63767],\n",
    "                                 'X23': [-0.28059798, 24.657183]}, \n",
    "                     outcome_name='outcome')\n",
    "\n",
    "    exp = dice_ml.Dice(d, m)\n",
    "    path_to_DICE_cf = 'Dice_cf'\n",
    "    path_to_GE_cf = 'Ge_cf'\n",
    "    \n",
    "    for i in os.listdir(input_folder):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        filename = input_folder + '/' + i + '/' \"final_gen.csv\"\n",
    "        input_array_location = input_folder + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        print(input)\n",
    "        input_scaled = scale_input(scaler, input, columns_to_standardize)\n",
    "        # print(input_scaled[0])\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "        data['o_1_mod'] = data.apply(lambda row: calculate_o_1(row['Phenotype'], input, model, scaler, columns_to_standardize), axis=1)\n",
    "        data = data.sort_values(by=['o_1_mod'])\n",
    "        data = data[data['o_1_mod'] > 0.50]\n",
    "        \n",
    "        number_of_counterfactuals = data.shape[0]\n",
    "        average_cf_count.append(number_of_counterfactuals)\n",
    "        input_dice = pd.DataFrame(data=[input_scaled[0]], columns=features)\n",
    "        print(number_of_counterfactuals)\n",
    "        # print(input_dice.head())\n",
    "        # print(feature_dict)\n",
    "        dice_exp = exp.generate_counterfactuals(input_dice, total_CFs=number_of_counterfactuals, desired_class=\"opposite\")\n",
    "        isExist = os.path.exists(path_to_DICE_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_DICE_cf)\n",
    "        # print(dice_exp.cf_examples_list[0].final_cfs_df.head())\n",
    "        dice_df_scaled = dice_exp.cf_examples_list[0].final_cfs_df\n",
    "        dice_df_original = inverse(dice_df_scaled, scaler, columns_to_standardize)\n",
    "        dice_df_original.to_csv(path_or_buf= path_to_DICE_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "        evolved_x = []\n",
    "    \n",
    "        for phenotype in data['Phenotype'].tolist():\n",
    "            x_out = apply_phenotype(input, phenotype)\n",
    "            evolved_x.append(x_out)\n",
    "            \n",
    "        GE_df = pd.DataFrame(data=evolved_x, columns=features)\n",
    "        isExist = os.path.exists(path_to_GE_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_GE_cf)\n",
    "        GE_df.to_csv(path_to_GE_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "    print(sum(average_cf_count)/len(average_cf_count))\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:44:49.893900Z",
     "start_time": "2024-06-29T22:44:49.881351Z"
    }
   },
   "id": "1fa52ba3335ea32a",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330000      1      1      1     34      0      0      0      0      0\n",
      "      0 138009 141253 130567 128257 116988 105961   7015   7000  10007\n",
      "   6500   6600   9000]\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 24)\n",
      "[390000      0      1      1     38      0      0      0      0      0\n",
      "      0 164418 167501 134282 128701 131529 135242   9000   7027   5000\n",
      "   5000   6000   5000]\n",
      "262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170000      0      1      2     28      0      0      0      0      0\n",
      "      0  56766  59811  61987  63849  66276  68207   4000   3638   3500\n",
      "   3500   3000   3000]\n",
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 24)\n",
      "[420000      0      2      1     29      0      0      0      0      0\n",
      "      0  48455  34993  35340  54763  59037  60290   2011   3000  20000\n",
      "   5000   2000   3000]\n",
      "162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[640000      0      2      2     39      0      0      0      0      0\n",
      "      0 119887 123223 119211 118722 105197  93921  10000  10000  10535\n",
      "  15000   5000  13627]\n",
      "177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 24)\n",
      "[280000      0      2      1     30      0      0      0      0      0\n",
      "      0  71770  74066  75907  77723  79550  81801   4000   3000   3000\n",
      "   3000   3500   4000]\n",
      "172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 33.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360000      0      1      2     27      0      0      0      0      0\n",
      "      0 130640 120058 110795 101668  78730  66682   4500   4100   4208\n",
      "   3000   2300   1800]\n",
      "268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268, 24)\n",
      "[180000      0      2      1     28      0      0      0      0      0\n",
      "      0  85557  73121  68650  67895  68442  70131   3200   2500   3000\n",
      "   2500   3000   5000]\n",
      "328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230000      0      1      1     27      0      0      0      0      0\n",
      "      0 104001 106155 111244 116300 121346 130318   4000   6000   6000\n",
      "   6000  10000  11058]\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 24)\n",
      "[310000      0      2      2     26      0      0      0      0      0\n",
      "      0  87717  93707  83632  81133  75499  73540   9156   2782   4013\n",
      "   2688   2651   2652]\n",
      "255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340000      1      2      1     31      0      0      0      0      0\n",
      "      0  63098  64417  65752  69639  80057  83713   2338   2406   5000\n",
      "  11610   5000   2971]\n",
      "133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 24)\n",
      "[200000      1      1      2     33      0      0      0      2      0\n",
      "      0  54713  58184  62286  61305  62846  42634   5000   5700   2000\n",
      "   3000   2000   1000]\n",
      "215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310000      1      1      2     32      0      0      0      0      0\n",
      "      0  59901  62147  62102  65875  60387  43328  10020   6031  10057\n",
      "   5028   5060   4223]\n",
      "174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 24)\n",
      "[480000      0      1      2     32     -2     -2     -2     -2     -2\n",
      "     -2  11872  38933  23479  52177  54005  53853  40000  23479  52209\n",
      "  54005  54500  42321]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 24)\n",
      "[430000      0      2      1     42      0      0      0      0      0\n",
      "      0  89395  90052  90604  91200  92134  92834   3243   3200   3185\n",
      "   3500   3500   3420]\n",
      "163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 24)\n",
      "[280000      0      2      2     38      0      0      0      0      0\n",
      "      0  92579  94451  96041  98301  74624  75173   4300   4000   4033\n",
      "   3000   3300   3500]\n",
      "264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 24)\n",
      "[320000      0      1      2     31      0      0      0      0      0\n",
      "      0  77052  65457  62680  62597  60080  55314   3000   3000   3017\n",
      "   2100   3000   3000]\n",
      "277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(277, 24)\n",
      "[300000      1      1      2     45      0      0      0      0      0\n",
      "      0  62296  64460  56439  53637  55981  58270   3000   3000   3000\n",
      "   3000   3000   3000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 24)\n",
      "[500000      0      2      1     40      0      0      0      0      0\n",
      "      0 215508 214460 220047 217920 159393 149626  10004  10025  10294\n",
      "   6046   5076   5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 24)\n",
      "[270000      1      2      1     35      0      0      0      0      0\n",
      "      0  48465  45898  46765  55438  54285  54198   1737   2000  10000\n",
      "   1461   1492    899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 24)\n",
      "[500000      0      1      2     37      0      0      0      0      0\n",
      "      0  80846  74776  73558  71055  61248  40737   3032   3200   1946\n",
      "   1734   2000   4128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 24)\n",
      "[300000      0      1      1     31      0      0      0      0      0\n",
      "      0 147277 149893 152529 152882 113347 114554   7000   7000   6000\n",
      "   4084   4056   4300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 24)\n",
      "[470000      1      1      2     31      0      0      0      0      0\n",
      "      0  99931  95096  80388  75631  71464  65915   5070   4019   2019\n",
      "   2120   2096   1744]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 24)\n",
      "[390000      0      1      2     43      0      0      0      0      0\n",
      "      0  90294  87292  88335  89396  90769  91825   3200   3200   3200\n",
      "   3500   3300   4000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 24)\n",
      "[500000      1      2      2     33      0      0      0      0      0\n",
      "      0 134558 134503 114682 124240 131006 137911   5185  20031  20029\n",
      "  20058  20127  10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 24)\n",
      "[340000      0      1      1     46      0      0      0      0      0\n",
      "      0  94915  92955  89689  81996  83439  71239   3224   4000   3504\n",
      "   4349   3000   3098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206, 24)\n",
      "[500000      0      1      1     46      0      0      0      0      0\n",
      "     -1 196606  64144  49722  67909  61613  16932  10000  10000  20025\n",
      "  10000  20000  18000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 24)\n",
      "[210000      0      1      1     34      0      0      0      0      0\n",
      "      0  74261  75602  76062  76287  76971  77737   3500   3300   3000\n",
      "   3000   3000   3000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 24)\n",
      "[450000      1      1      2     26      0      0      0     -1     -1\n",
      "     -1  20571  37283  43482   5626  73516  11854  20000  20006   5676\n",
      "  74306  11889  13347]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154, 24)\n",
      "[180000      0      6      2     47      0      0      0      0      0\n",
      "      0 167915 163279 166994 150812 123957  55778   6028   7758   5188\n",
      "   4570   1876   1701]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154, 24)\n",
      "196.63333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_folder = './../output/NSGAIII_multi/'\n",
    "create_dice_cf(input_folder, scaler, model, columns_to_standardize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:44:53.898345Z",
     "start_time": "2024-06-29T22:44:50.759254Z"
    }
   },
   "id": "ad52ab336a622bb6",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_NSGAII_cf(input_folder, model, scaler, columns_to_standardize):\n",
    "    \n",
    "    features =  ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11','X12', 'X13',\n",
    "            'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23']\n",
    "\n",
    "    \n",
    "\n",
    "    path_to_NSGAII_cf = 'Ge_NSGAII_cf'\n",
    "    \n",
    "    for i in os.listdir(input_folder):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        filename = input_folder + '/' + i + '/' \"final_gen.csv\"\n",
    "        input_array_location = input_folder + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        data = pd.read_csv(filename)\n",
    "\n",
    "        \n",
    "        # print(number_of_counterfactuals)\n",
    "        \n",
    "        data['o_1_mod'] = data.apply(lambda row: calculate_o_1(row['Phenotype'], input, model, scaler, columns_to_standardize), axis=1)\n",
    "        data = data.sort_values(by=['o_1_mod'])\n",
    "        data = data[data['o_1_mod'] > 0.50]\n",
    "        number_of_counterfactuals = data.shape[0]\n",
    "        \n",
    "        evolved_x = []\n",
    "    \n",
    "        for phenotype in data['Phenotype'].tolist():\n",
    "            x_out = apply_phenotype(input, phenotype)\n",
    "            evolved_x.append(x_out)\n",
    "            \n",
    "        GE_df = pd.DataFrame(data=evolved_x, columns=features)\n",
    "        isExist = os.path.exists(path_to_NSGAII_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_NSGAII_cf)\n",
    "        GE_df.to_csv(path_to_NSGAII_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "        \n",
    "input_folder = './../output/NSGAII_multi/'\n",
    "create_NSGAII_cf(input_folder, model, scaler, columns_to_standardize)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:45:42.534012Z",
     "start_time": "2024-06-29T22:45:40.349446Z"
    }
   },
   "id": "9fd18d664e96dbc6",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b770c6da0ac34bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
