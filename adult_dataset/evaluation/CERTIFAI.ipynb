{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:48:44.235640Z",
     "start_time": "2024-06-29T22:48:43.006544Z"
    }
   },
   "outputs": [],
   "source": [
    "from CERTIFAI import CERTIFAI\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd \n",
    "from pickle import dump , load"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    return np.load(data)\n",
    "\n",
    "\n",
    "class AdultClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(13, 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 128)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(128, 32)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.hidden4 = nn.Linear(32, 16)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.output = nn.Linear(16, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.act1(self.hidden1(x)))\n",
    "        x = self.dropout(self.act2(self.hidden2(x)))\n",
    "        x = self.dropout(self.act3(self.hidden3(x)))\n",
    "        x = self.dropout(self.act4(self.hidden4(x)))\n",
    "        # x = self.output(x)\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def load_model():\n",
    "    model = torch.load('./../model_training/adult_credit__model')\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, input, scaler, columns_to_standardize):\n",
    "    model.eval()\n",
    "    # print(input)\n",
    "    input = input.reshape(-1, 13)\n",
    "    input = torch.tensor(input, dtype=torch.float32)\n",
    "    input = input.numpy()\n",
    "    input[:, columns_to_standardize] = scaler.transform(input[:, columns_to_standardize])\n",
    "    input = torch.from_numpy(input).type(torch.float)\n",
    "    with torch.no_grad():\n",
    "        prob = model(input)\n",
    "    return prob.tolist()[0][0]\n",
    "\n",
    "def load_scaler(scaler_loc):\n",
    "    return load(open(scaler_loc, 'rb'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:48:44.241757Z",
     "start_time": "2024-06-29T22:48:44.236441Z"
    }
   },
   "id": "89f26eeee7c67ce5",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def scale_input(scaler, input, columns_to_standardize):\n",
    "    input = input.reshape(-1, 13)\n",
    "    input = torch.tensor(input, dtype=torch.float32)\n",
    "    input = input.numpy()\n",
    "    input[:, columns_to_standardize] = scaler.transform(input[:, columns_to_standardize])\n",
    "    return input\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T22:48:44.244764Z",
     "start_time": "2024-06-29T22:48:44.242682Z"
    }
   },
   "id": "bdbe6ac2abdaa0a2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# file_path = \"./../output/NSGAIII/1/input_data.npy\"\n",
    "# input_array = load_data(file_path)\n",
    "model = load_model()\n",
    "scaler = load_scaler('./../model_training/StandardScaler.pkl')\n",
    "bounds = [(17, 90), (0, 8), (12285, 1455436), (1, 16), (0, 6), (0, 14), (0, 5), (0, 4), (0, 1), (0, 99999), (0, 4365),\n",
    "              (1, 99), (0, 41)]\n",
    "min_array = np.array([17, 0, 12285, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
    "max_array = np.array([90, 8, 1455436, 16, 6, 14, 5, 4, 1, 99999, 4365, 99, 41])\n",
    "columns_to_standardize = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
    "scaled_min = scale_input(scaler, min_array, columns_to_standardize)\n",
    "scaled_max = scale_input(scaler, max_array, columns_to_standardize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:52:32.840483Z",
     "start_time": "2024-06-25T11:52:32.833038Z"
    }
   },
   "id": "bc3fa81df4f273eb",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 13)\n"
     ]
    }
   ],
   "source": [
    "def inverse_transform(df_scaled, scaler, columns_to_standardize):\n",
    "    df_values = df_scaled.values\n",
    "    print(df_values.shape)\n",
    "    df_values[:, columns_to_standardize] = scaler.inverse_transform(df_values[:, columns_to_standardize])\n",
    "    df_original = pd.DataFrame(df_values, columns=df_scaled.columns)\n",
    "    return df_original\n",
    "\n",
    "def transform(df, scaler, columns_to_standardize):\n",
    "    df_values = df.values\n",
    "    print(df_values.shape)\n",
    "    df_values[:, columns_to_standardize] = scaler.transform(df_values[:, columns_to_standardize])\n",
    "    df_original = pd.DataFrame(df_values, columns=df.columns)\n",
    "    return df_original\n",
    "\n",
    "def create_pd_dataframe(input_folder, scaler, columns_to_standardize):\n",
    "    features = ['age','workclass','fnlwgt','education-num','marital-status','occupation','relationship','race','sex',\n",
    "            'capital-gain','capital-loss','hours-per-week','native-country']\n",
    "    max = [90, 8, 1455436, 16, 6, 14, 5, 4, 1, 99999, 4365, 99, 41]\n",
    "    min = [17, 0, 12285, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "    input_data_list = []\n",
    "    order_list = []\n",
    "    for i in os.listdir(input_folder):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        # print(i)\n",
    "        input_array_location = input_folder + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        input_data_list.append(input)\n",
    "        order_list.append(i)\n",
    "    input_data_list.append(min)\n",
    "    input_data_list.append(max)\n",
    "    data_frame  = pd.DataFrame(data=input_data_list, columns=features)\n",
    "    data_frame = transform(data_frame, scaler, columns_to_standardize)\n",
    "    return data_frame, order_list\n",
    "\n",
    "input_df, order_list = create_pd_dataframe(\"./../output/NSGAIII_multi/\", scaler, columns_to_standardize )\n",
    "input_df.to_csv('certif_input_df.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:52:33.204723Z",
     "start_time": "2024-06-25T11:52:33.191126Z"
    }
   },
   "id": "baa17857956504e3",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "certifai_instance = CERTIFAI.from_csv('certif_input_df.csv')\n",
    "print(type(certifai_instance.tab_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:52:33.704091Z",
     "start_time": "2024-06-25T11:52:33.697955Z"
    }
   },
   "id": "cf121afe1d458a89",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating counterfactual(s) for sample 31:  97%|█████████▋| 31/32 [02:30<00:04,  4.84s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 13)) while a minimum of 1 is required by check_pairwise_arrays.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcertifai_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclassification\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mL2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/v1.0 grape_dhiraj/pythonProject/adult_dataset/evaluation/CERTIFAI.py:919\u001B[0m, in \u001B[0;36mCERTIFAI.fit\u001B[0;34m(self, model, x, model_input, pytorch, classification, generations, distance, constrained, class_specific, select_retain, gen_retain, final_k, normalisation, fixed, verbose, experiment)\u001B[0m\n\u001B[1;32m    915\u001B[0m final_generation \u001B[38;5;241m=\u001B[39m crossed_generation\u001B[38;5;241m.\u001B[39mloc[diff_prediction]\n\u001B[1;32m    917\u001B[0m \u001B[38;5;66;03m# print(sample.shape, final_generation.shape)\u001B[39;00m\n\u001B[0;32m--> 919\u001B[0m final_distances \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistance\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_generation\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    921\u001B[0m final_generation, counterfacts_fit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_counterfacts_list_dictionary(\n\u001B[1;32m    922\u001B[0m     counterfacts_list \u001B[38;5;241m=\u001B[39m final_generation\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mtolist(),\n\u001B[1;32m    923\u001B[0m     distances \u001B[38;5;241m=\u001B[39m final_distances, \n\u001B[1;32m    924\u001B[0m     fitness_dict \u001B[38;5;241m=\u001B[39m counterfacts_fit,\n\u001B[1;32m    925\u001B[0m     retain_k \u001B[38;5;241m=\u001B[39m gen_retain, \n\u001B[1;32m    926\u001B[0m     start \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(counterfacts_fit))\n\u001B[1;32m    928\u001B[0m counterfacts\u001B[38;5;241m.\u001B[39mextend(final_generation)\n",
      "File \u001B[0;32m~/Downloads/grape_dhiraj/pythonProject/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m~/Downloads/grape_dhiraj/pythonProject/.venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:319\u001B[0m, in \u001B[0;36meuclidean_distances\u001B[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m    234\u001B[0m     {\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    244\u001B[0m     X, Y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, Y_norm_squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, X_norm_squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    245\u001B[0m ):\n\u001B[1;32m    246\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;124;03m    Compute the distance matrix between each pair from a vector array X and Y.\u001B[39;00m\n\u001B[1;32m    248\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;124;03m           [1.41421356]])\u001B[39;00m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 319\u001B[0m     X, Y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_pairwise_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m X_norm_squared \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    322\u001B[0m         X_norm_squared \u001B[38;5;241m=\u001B[39m check_array(X_norm_squared, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/Downloads/grape_dhiraj/pythonProject/.venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:172\u001B[0m, in \u001B[0;36mcheck_pairwise_arrays\u001B[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    164\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m    165\u001B[0m         X,\n\u001B[1;32m    166\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    170\u001B[0m         estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[1;32m    171\u001B[0m     )\n\u001B[0;32m--> 172\u001B[0m     Y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m precomputed:\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m Y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[0;32m~/Downloads/grape_dhiraj/pythonProject/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1072\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m   1070\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n\u001B[1;32m   1071\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_samples \u001B[38;5;241m<\u001B[39m ensure_min_samples:\n\u001B[0;32m-> 1072\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1073\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m sample(s) (shape=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) while a\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1074\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m minimum of \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m is required\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1075\u001B[0m             \u001B[38;5;241m%\u001B[39m (n_samples, array\u001B[38;5;241m.\u001B[39mshape, ensure_min_samples, context)\n\u001B[1;32m   1076\u001B[0m         )\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_features \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m   1079\u001B[0m     n_features \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mValueError\u001B[0m: Found array with 0 sample(s) (shape=(0, 13)) while a minimum of 1 is required by check_pairwise_arrays."
     ]
    }
   ],
   "source": [
    "certifai_instance.fit(model, generations=200, verbose=True, final_k= 9, classification=False, experiment=True, distance='L2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:55:04.263073Z",
     "start_time": "2024-06-25T11:52:34.071427Z"
    }
   },
   "id": "982c9a851412a458",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def save_certif_counterfactuals(certifai_instance_results, order_list, scaler, columns_to_standardize):\n",
    "    certif_save_loc = 'Certif_cf'\n",
    "    features =['age','workclass','fnlwgt','education-num','marital-status','occupation','relationship','race','sex',\n",
    "            'capital-gain','capital-loss','hours-per-week','native-country']\n",
    "    \n",
    "    for i in range(len(order_list)):\n",
    "        cf_list = certifai_instance_results[i][1]\n",
    "        \n",
    "        certif_df  = pd.DataFrame(data=cf_list, columns=features)\n",
    "        certif_df = inverse_transform(certif_df, scaler, columns_to_standardize)\n",
    "        isExist = os.path.exists(certif_save_loc)\n",
    "        if not isExist:\n",
    "            os.makedirs(certif_save_loc)\n",
    "        certif_df.to_csv(certif_save_loc + \"/\" + order_list[i] + '.csv'  , index=False)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:55:54.812868Z",
     "start_time": "2024-06-25T11:55:54.811282Z"
    }
   },
   "id": "f2b297da4f76b1f8",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n",
      "(9, 13)\n"
     ]
    }
   ],
   "source": [
    "save_certif_counterfactuals(certifai_instance.results, order_list, scaler, columns_to_standardize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:55:55.533054Z",
     "start_time": "2024-06-25T11:55:55.515703Z"
    }
   },
   "id": "9b9cd0d25d264060",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c94a56e424825c07"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
