{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:02.547444Z",
     "start_time": "2024-06-25T11:44:01.434288Z"
    }
   },
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pickle import dump , load\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AdultClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(13, 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 128)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(128, 32)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.hidden4 = nn.Linear(32, 16)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.output = nn.Linear(16, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.act1(self.hidden1(x)))\n",
    "        x = self.dropout(self.act2(self.hidden2(x)))\n",
    "        x = self.dropout(self.act3(self.hidden3(x)))\n",
    "        x = self.dropout(self.act4(self.hidden4(x)))\n",
    "        # x = self.output(x)\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def load_model():\n",
    "    model = torch.load('./../model_training/adult_credit__model')\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def eval_model(model, input, scaler, columns_to_standardize):\n",
    "    model.eval()\n",
    "    # print(input)\n",
    "    input = input.reshape(-1, 13)\n",
    "    input = torch.tensor(input, dtype=torch.float32)\n",
    "    input = input.numpy()\n",
    "    input[:, columns_to_standardize] = scaler.transform(input[:, columns_to_standardize])\n",
    "    input = torch.from_numpy(input).type(torch.float)\n",
    "    with torch.no_grad():\n",
    "        prob = model(input)\n",
    "    return prob.tolist()[0][0]\n",
    "\n",
    "def load_scaler(scaler_loc):\n",
    "    return load(open(scaler_loc, 'rb'))\n",
    "\n",
    "columns_to_standardize = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:02.554710Z",
     "start_time": "2024-06-25T11:44:02.551553Z"
    }
   },
   "id": "37b1ad538e7272d4",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = load_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:02.558098Z",
     "start_time": "2024-06-25T11:44:02.553930Z"
    }
   },
   "id": "d622006bf8a2603e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    return np.load(data)\n",
    "\n",
    "\n",
    "def create_dataframe_from_list_of_arrays(arrays, column_names=None):\n",
    "    data= []\n",
    "    if not arrays:\n",
    "        raise ValueError(\"The list of arrays is empty\")\n",
    "    \n",
    "    # Check if all arrays have the same length\n",
    "    length = len(arrays[0])\n",
    "    if not all(len(arr) == length for arr in arrays):\n",
    "        raise ValueError(\"All arrays must have the same length\")\n",
    "    \n",
    "    # Create a dictionary for DataFrame creation\n",
    "\n",
    "    if len(column_names) != length:\n",
    "        print(len(column_names), len(arrays))\n",
    "        raise ValueError(\"Number of column names must match the number of arrays\")\n",
    "    for i in arrays:\n",
    "        data.append({column_names[j]: i[j] for j in range(len(i))})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def create_data(folder_location, column_names):\n",
    "    input_list = []\n",
    "    for i in os.listdir(folder_location):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        input_array_location = folder_location + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        print(input)\n",
    "        input_list.append(input)\n",
    "    \n",
    "    df = create_dataframe_from_list_of_arrays(input_list, column_names)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:02.561872Z",
     "start_time": "2024-06-25T11:44:02.560568Z"
    }
   },
   "id": "597c6f762ec32c3d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def scale_input(scaler, input, columns_to_standardize):\n",
    "    input = input.reshape(-1, 13)\n",
    "    input = torch.tensor(input, dtype=torch.float32)\n",
    "    input = input.numpy()\n",
    "    input[:, columns_to_standardize] = scaler.transform(input[:, columns_to_standardize])\n",
    "    return input\n",
    "\n",
    "\n",
    "def calculate_o_1(phenotype, input, model, scaler, columns_to_standardize):\n",
    "    mod_in = apply_phenotype(input, phenotype)\n",
    "    o_1 = eval_model(model, mod_in, scaler, columns_to_standardize)\n",
    "    return o_1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:02.565092Z",
     "start_time": "2024-06-25T11:44:02.563329Z"
    }
   },
   "id": "df5e5f857b75e42c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scaler = load_scaler('./../model_training/StandardScaler.pkl')\n",
    "bounds = [(17, 90), (0, 8), (12285, 1455436), (1, 16), (0, 6), (0, 14), (0, 5), (0, 4), (0, 1), (0, 99999), (0, 4365),\n",
    "              (1, 99), (0, 41)]\n",
    "min_array = np.array([17, 0, 12285, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
    "max_array = np.array([90, 8, 1455436, 16, 6, 14, 5, 4, 1, 99999, 4365, 99, 41])\n",
    "scaled_min = scale_input(scaler, min_array, columns_to_standardize)\n",
    "scaled_max = scale_input(scaler, max_array, columns_to_standardize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:02.568564Z",
     "start_time": "2024-06-25T11:44:02.566491Z"
    }
   },
   "id": "dadff05f57ef1940",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.8279953   2.9207141  12.163467    2.05989     2.6726549   1.7228366\n",
      "   2.3551893   0.3582251   1.          9.047189    8.810054    4.685987\n",
      "   0.54877317]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_max)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:02.572108Z",
     "start_time": "2024-06-25T11:44:02.569394Z"
    }
   },
   "id": "88be52cf047e8f72",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.8245884  -2.8898754  -1.6928626  -3.6334774  -1.8149168  -1.6631873\n",
      "  -0.72823167 -4.633004    0.         -0.1972487  -0.25733045 -3.4018977\n",
      "  -5.0974035 ]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_min)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:02.583024Z",
     "start_time": "2024-06-25T11:44:02.571134Z"
    }
   },
   "id": "a783fedb4d70968f",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def apply_phenotype(array, phenotype):\n",
    "    # Split the phenotype string into individual operations\n",
    "    operations = phenotype.split(';')\n",
    "    x = copy.deepcopy(array)\n",
    "    # Iterate over each operation and execute it\n",
    "    for operation in operations:\n",
    "        # Strip any leading/trailing whitespace from the operation\n",
    "        operation = operation.strip()\n",
    "        \n",
    "        # Use the exec function to execute the operation on the array\n",
    "        if operation:\n",
    "            exec(operation)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def inverse(dice_df_scaled, scaler, columns_to_standardize):\n",
    "    df_values = dice_df_scaled.values\n",
    "    print(df_values.shape)\n",
    "    df_values[:, columns_to_standardize] = scaler.inverse_transform(df_values[:, columns_to_standardize])\n",
    "    df_original = pd.DataFrame(df_values, columns=dice_df_scaled.columns)\n",
    "    return df_original\n",
    "    \n",
    "\n",
    "\n",
    "def create_dice_cf(input_folder, scaler, model, columns_to_standardize):\n",
    "    \n",
    "    features = ['age','workclass','fnlwgt','education-num','marital-status','occupation','relationship','race','sex',\n",
    "            'capital-gain','capital-loss','hours-per-week','native-country']\n",
    "    backend = 'PYT'  # needs pytorch installed\n",
    "    ML_modelpath = './../model_training/adult_credit__model'\n",
    "    m = dice_ml.Model(model_path=ML_modelpath, backend=backend)\n",
    "    \n",
    "    d = dice_ml.Data(features={'age': [-1.8245884,3.8279953],\n",
    "                           'workclass' : [-2.8898754, 2.9207141],\n",
    "                           'fnlwgt' : [-1.6928626, 12.163467],\n",
    "                           'education-num' : [-3.6334774,   2.05989 ],\n",
    "                           'marital-status' : [-1.8149168, 2.6726549],\n",
    "                           'occupation' : [-1.6631873,  1.7228366],\n",
    "                           'relationship': [-0.72823167, 2.3551893],\n",
    "                           'race' : [-4.633004,  0.3582251],\n",
    "                           'sex' : [0.0, 1.0],\n",
    "                           'capital-gain' : [ -0.1972487,  9.047189 ],\n",
    "                           'capital-loss': [  -0.25733045,    8.810054],\n",
    "                           'hours-per-week' : [ -3.4018977,  4.685987],\n",
    "                           'native-country' : [-5.0974035, 0.54877317]},\n",
    "                 outcome_name='outcome')\n",
    "\n",
    "    exp = dice_ml.Dice(d, m)\n",
    "    path_to_DICE_cf = 'Dice_cf'\n",
    "    path_to_GE_cf = 'Ge_cf'\n",
    "    \n",
    "    for i in os.listdir(input_folder):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        filename = input_folder + '/' + i + '/' \"final_gen.csv\"\n",
    "        input_array_location = input_folder + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        # print(input.shape)\n",
    "        input_scaled = scale_input(scaler, input, columns_to_standardize)\n",
    "        # print(input_scaled[0].shape)\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "        data['o_1_mod'] = data.apply(lambda row: calculate_o_1(row['Phenotype'], input, model, scaler, columns_to_standardize), axis=1)\n",
    "        data = data.sort_values(by=['o_1_mod'])\n",
    "        data = data[data['o_1_mod'] > 0.50]\n",
    "        \n",
    "        number_of_counterfactuals = data.shape[0]\n",
    "        # print(number_of_counterfactuals)\n",
    "        input_dice = pd.DataFrame(data=[input_scaled[0]], columns=features)\n",
    "        print(number_of_counterfactuals)\n",
    "        dice_exp = exp.generate_counterfactuals(input_dice, total_CFs=number_of_counterfactuals, desired_class=\"opposite\")\n",
    "        isExist = os.path.exists(path_to_DICE_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_DICE_cf)\n",
    "        # print(dice_exp.cf_examples_list[0].final_cfs_df.head())\n",
    "        dice_df_scaled = dice_exp.cf_examples_list[0].final_cfs_df\n",
    "        dice_df_original = inverse(dice_df_scaled, scaler, columns_to_standardize)\n",
    "        dice_df_original.to_csv(path_or_buf= path_to_DICE_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "        evolved_x = []\n",
    "    \n",
    "        for phenotype in data['Phenotype'].tolist():\n",
    "            x_out = apply_phenotype(input, phenotype)\n",
    "            evolved_x.append(x_out)\n",
    "            \n",
    "        GE_df = pd.DataFrame(data=evolved_x, columns=features)\n",
    "        isExist = os.path.exists(path_to_GE_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_GE_cf)\n",
    "        GE_df.to_csv(path_to_GE_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:03.358238Z",
     "start_time": "2024-06-25T11:44:03.333667Z"
    }
   },
   "id": "1fa52ba3335ea32a",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 14)\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 37.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 14)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 14)\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 14)\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 14)\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 14)\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 14)\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 14)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 14)\n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 14)\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 14)\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 14)\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 14)\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 14)\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 14)\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 14)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 14)\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 14)\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 14)\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14)\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 14)\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 14)\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_folder = './../output/NSGAIII_multi/'\n",
    "create_dice_cf(input_folder, scaler, model, columns_to_standardize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:07.119605Z",
     "start_time": "2024-06-25T11:44:04.306276Z"
    }
   },
   "id": "ad52ab336a622bb6",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_NSGAII_cf(input_folder, model, scaler, columns_to_standardize):\n",
    "    \n",
    "    features = ['age','workclass','fnlwgt','education-num','marital-status','occupation','relationship','race','sex',\n",
    "            'capital-gain','capital-loss','hours-per-week','native-country']\n",
    "\n",
    "    \n",
    "\n",
    "    path_to_NSGAII_cf = 'Ge_NSGAII_cf'\n",
    "    \n",
    "    for i in os.listdir(input_folder):\n",
    "        if i=='.DS_Store':\n",
    "            continue\n",
    "        filename = input_folder + '/' + i + '/' \"final_gen.csv\"\n",
    "        input_array_location = input_folder + '/' + i + '/' + 'input_data.npy'\n",
    "        input = load_data(input_array_location)\n",
    "        data = pd.read_csv(filename)\n",
    "\n",
    "        \n",
    "        # print(number_of_counterfactuals)\n",
    "        \n",
    "        data['o_1_mod'] = data.apply(lambda row: calculate_o_1(row['Phenotype'], input, model, scaler, columns_to_standardize), axis=1)\n",
    "        data = data.sort_values(by=['o_1_mod'])\n",
    "        data = data[data['o_1_mod'] > 0.50]\n",
    "        number_of_counterfactuals = data.shape[0]\n",
    "        \n",
    "        evolved_x = []\n",
    "    \n",
    "        for phenotype in data['Phenotype'].tolist():\n",
    "            x_out = apply_phenotype(input, phenotype)\n",
    "            evolved_x.append(x_out)\n",
    "            \n",
    "        GE_df = pd.DataFrame(data=evolved_x, columns=features)\n",
    "        isExist = os.path.exists(path_to_NSGAII_cf)\n",
    "        if not isExist:\n",
    "            os.makedirs(path_to_NSGAII_cf)\n",
    "        GE_df.to_csv(path_to_NSGAII_cf + \"/\" + str(i) + '.csv'  , index=False)\n",
    "        \n",
    "        \n",
    "input_folder = './../output/NSGAII_multi/'\n",
    "create_NSGAII_cf(input_folder, model, scaler, columns_to_standardize)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-25T11:44:18.321161Z",
     "start_time": "2024-06-25T11:44:16.402345Z"
    }
   },
   "id": "9fd18d664e96dbc6",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b770c6da0ac34bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
